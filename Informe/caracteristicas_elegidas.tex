\chapter{Representación de las preguntas}\label{capitulo-features}

Una parte importante de cualquier problema que aborde el lenguaje natural es la forma de representarlo. Las características relevantes para describir un problema dependen fuertemente del mismo y de su solución, si bien existen numerosos ejemplos de trabajos previos a tomar como modelo. El siguiente paso en esta tesis es identificar qué características de una pregunta son indicativas de su clase semántica, lo cual no tiene una respuesta intuitiva.

Nuestra primera aproximación fue utilizar criterios estándares en la categorización de texto como los lemas de las palabras y sus etiquetas POS. \citet{Sebastiani-text-categorization} describe que a pesar de su simpleza son representaciones muy poderosas y que otras más complejas no necesariamente llevarán a un mejor desempeño del clasificador. A pesar de ser formas superficiales del lenguaje, son una manifestación de la semántica ya que ésta es su causa latente.

Una representación posible pero que descartamos es utilizar las palabras o el lexico de las preguntas. Este tipo de representación es redundante con respecto a los lemas ya que contienen información muy similar, mientras que tienen una dispersión mucho mayor. Por ejemplo, el lema ``comer'' incluye la información de las palabras ``come'', ``comía'', ``comeremos'', etc.

Además de lemas es común el uso de n-gramas para la representación de texto. Un n-grama de lemas es una secuencia de longitud n extraída del texto. Ilustramos este concepto con un ejemplo:

\begin{example} Descomposición de una oración en bigramas y trigramas.

Oración: ``El gato come pescado.''

Lemas: ``el'', ``gato'', ``comer'', ``pescado'', ``.''.

Bigramas: ``el gato'', ``gato comer'', ``comer pescado'', ``pescado .''.

Trigramas: ``el gato comer'', ``gato comer pescado'', ``comer pescado .''.

\end{example}

Se espera que los n-gramas representen además de las palabras del texto la relación que existe entre ellas derivada de su posición relativa. Sin embargo, estas combinaciones crecen exponencialmente con el tamaño del corpus y dan lugar a matrices muy dispersas, ya que pocos n-gramas ocurren en muchas instancias del corpus. Por ello decidimos limitarnos a bigramas y trigramas.

Los n-gramas pueden construirse no sólo a partir de los lemas sino también incluyendo etiquetas POS. Este tipo de estructuras son útiles cuando queremos representar, por ejemplo, ``la palabra comer seguida de un sustantivo''. Utilizaremos bigramas combinados de la forma (lema, POS) y (POS, lema), a las que llamamos bigramas mezclados.

\section{Subpatrones}

Como mostramos en el ejemplo \ref{preguntas-similares} algunas preguntas tienen tanto lemas como etiquetas POS muy similares y sin embargo pertenecen a clases distintas. La forma en la que Quepy distingue estos casos es utilizando la estructura de la frase, representada en sus patrones. Por eso, decidimos utilizar además como característica los patrones que concuerdan con la pregunta.

Esta representación por sí sola tampoco mejora nuestra situación inicial, ya que sólo reconoce las preguntas que corresponden de forma exacta a un patrón. La solución que encontramos para este problema fue dividir cada patrón en todos sus posibles subpatrones y determinar con cuales de todos estos subpatrones concuerda cada instancia.

\begin{example}\label{ejemplos-subpatrones} Subpatrones del ejemplo \ref{regex}.
\begin{enumerate}
\item \begin{lstlisting}
Lemma("what") + Lemma("be") + Question(Pos("DT"))
    + Group(Pos("NN"), "target") + Question(Pos("."))
\end{lstlisting}

\item
\begin{lstlisting}
Lemma("what") + Lemma("be") + Question(Pos("DT"))
+ Group(Pos("NN"), "target")
\end{lstlisting}

\item
\begin{lstlisting}
Lemma("what") + Lemma("be") + Question(Pos("DT"))
\end{lstlisting}

\item
\begin{lstlisting}
Lemma("what") + Lemma("be")
\end{lstlisting}

\item
\begin{lstlisting}
Lemma("what")
\end{lstlisting}

\item
\begin{lstlisting}
Lemma("be")
\end{lstlisting}

\item
\begin{lstlisting}
Lemma("be") + Question(Pos("DT"))
+ Group(Pos("NN"), "target") + Question(Pos("."))
\end{lstlisting}

\item
\begin{lstlisting}
...
\end{lstlisting}
\end{enumerate}
\end{example}

%La aplicación de Quepy original contaba con 29 patrones a partir de los cuales generamos 153 patrones parciales. De nuestro corpus original, sólo 56 pregun
Cabe destacar que estos patrones incluyen mucha información presente en los lemas y en las etiquetas POS, concordando con ellas en algunos casos como los subpatrones 4, 5 y 6 del ejemplo \ref{ejemplos-subpatrones}.

\section{Nombres y tipos de entidades}

Existe un tipo más de característica que determina fuertemente la semántica de la pregunta. Recordemos que las ontologías son creadas colaborativamente por muchos usuarios que agregan porciones de datos e incluso definen el esquema de los mismos. Como resultado, la forma de acceder a una propiedad de una entidad dentro de la ontología está íntimamente ligada a la estructura que le dio el usuario al ingresar los datos. La misma propiedad como ``fecha de creación'' puede tener dos nombres distintos si nos referimos a entidades de tipo libro o de tipo película, llevando a la generación de consultas distintas. Por eso, en la situación que hemos propuesto, son necesarias dos clases semánticas en lugar de una, ya que las clases semánticas sirven de mediadoras entre la semántica y la ontología.

\begin{example} Ejemplos con semántica diferenciada por el tipo de la entidad.
    \begin{enumerate}
        \item ``Who are the actors of Titanic?''
        \item ``Who are the actors of Friends?''
    \end{enumerate}
En FreeBase, para obtener los actores que trabajaron en una película, como en el caso de la primera pregunta, debe utilizarse la relación ``/film/film/starring'', mientras que en el caso de una serie televisiva se utiliza ``/tv/tv\_program/regular\_cast''.
\end{example}

El indicio más certero de la clase semántica en estos casos es la entidad nombrada en la pregunta. Por ello, la incluimos como una característica más. Agregaremos los tipos de dicha entidad en la base de conocimiento extraídos de FreeBase. Cabe destacar que no todas las preguntas tienen una entidad, y en el caso de que sí tenga no siempre podemos reconocerla. Esto depende del módulo externo de reconocimiento de nombres de entidades (NERC). En el capítulo siguiente describiremos el sistema que utilizamos para esta tarea.

En resumen, las características propuestas para el sistema son:
\begin{itemize}
    \item Lemas, bigramas, trigramas y bigramas mezclados.
    \item Etiquetas POS.
    \item Concordancias a patrones parciales.
    \item Entidades nombradas.
    \item Tipos de las entidades nombradas.
\end{itemize}


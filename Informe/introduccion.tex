%\chapter*{Introducción}

Los sistemas de respuesta a preguntas sobre datos enlazados son un área naciente del procesamiento del lenguaje natural y particularmente del área de recuperación de información.

\citet{gupta_survey} destacan que existen dos formas principales de buscar la respuesta a una pregunta de un usuario. La primera de ellas, utilizada inicialmente, consiste de encontrar similitudes semánticas o sintácticas entre la pregunta y documentos de texto que pueden contener evidencias para la respuesta. La segunda, que abordaremos durante este trabajo, traduce la pregunta a un lenguaje formal para luego realizar consultas a una base de conocimiento estructurada.

La reciente posibilidad de manejo de grandes volúmenes de datos ha permitido la formación de grades bases de conocimiento, muchas de ellas públicas y disponibles online. Estas ontologías cambian ampliamente el paradigma utilizado hasta el momento, ya que dan estructura a los datos y permiten entonces extraer relaciones complejas entre sus entidades, como plantea \citet{ou_entailement}.

Sin embargo, el primer paso para la resolución de una pregunta es la formalización de la misma a partir del texto ingresado por el usuario, independientemente del método de extracción de información empleado a continuación. Aún así, la mayoría de los sistemas se centran en la búsqueda de la respuesta más que en la correcta interpretación de la pregunta, y en general se limitan a textos cortos y preguntas factuales.

Una aproximación que trata de simplificar la creación de sistemas de respuesta a preguntas es la de Quepy \footnote{http://quepy.machinalis.com/}: es una librería para la traducción automática de preguntas en lenguaje natural a un lenguaje de consultas formalizado. El programador define una serie de plantillas para cada tipo de pregunta que el sistema pueda procesar y su correspondiente interpretación en la base de conocimiento elegida.

Aunque Quepy está diseñado para simplificar la tarea de construcción de dichas reglas, el trabajo necesario para lograr cobertura amplia es todavía muy elevado por varios motivos:
\begin{itemize}
    \item Las plantillas deben ser desarrolladas por un experto de forma individual.
    \item El poder expresivo de las preguntas que soporte el sistema es lineal con respecto a la cantidad de plantillas generadas.
    \item Existe redundancia de información por falta de modularización ya que en muchos casos deben definirse patrones de preguntas muy similares. Por ejemplo, para las preguntas \textit{Who are the presidents of Argentina?} y \textit{Who are the children of the presidents of Argentina?} se necesitan dos plantillas que contienen la misma información utilizada para construir la parte de la consulta que representa \textit{presidents of Argentina}.
    \item Existen numerosas preguntas que son equivalentes y que no necesariamente se representan con la misma plantilla porque presentan diferentes formas superficiales. Por ejemplo las preguntas \textit{Where is Angelina Jolie from?} y \textit{Where was Angelina Jolie born?} tienen esencialmente la misma semántica.
    \item Debido a las grandes variaciones del lenguaje natural, se requiere un analista experto para lograr una cobertura completa de todas las reformulaciones para una misma semántica.
\end{itemize}

De todas las dificultades anteriores nos enfocaremos en las dos últimas ya que las consideramos prioritarias y, al solucionarlas, podemos ampliar la cobertura de los sistemas construidos sobre Quepy significativamente.

Nuestra propuesta es aplicar un clasificador automático sobre las preguntas donde cada clase es una de las posibles interpretaciones de Quepy. De esta forma, podemos ligar muchas más reformulaciones de la misma pregunta a su correspondiente semántica y lograr mayor cobertura.

La principal originalidad de nuestra aplicación se basa en utilizar como características las concordancias parciales con las plantillas de Quepy predefinidas por un programador. Consideramos que identifican claramente los aspectos relevantes para la correcta interpretación de la pregunta, y como tal son mejores representaciones.

Para evaluar el aporte de nuestro sistema consideramos que entrenar el clasificador con pocos patrones predefinidos nos ayudaría a percibir con más exactitud la posible mejora generada por su interacción con Quepy. Por ello, y debido a que no existen grandes corpus etiquetados para reformulaciones de preguntas, planteamos que un enfoque de aprendizaje activo es lo más adecuado.

El aprendizaje activo, como describe \citet{settles_active_learning_survey}, permite entrenar un clasificador automático con menor cantidad de instancias que en un entrenamiento automático pasivo y es beneficioso cuando se cuenta con muchos ejemplos no etiquetados pero donde la mayoría con redundantes. En nuestro entorno en particular se da este fenómeno, debido a que en un corpus no anotado estándar pocas de las preguntas caerán dentro de alguna de las clases semánticas de los patrones iniciales. Adicionalmente realizaremos experimentos para medir el impacto del aprendizaje activo sobre características en un entorno con clases minoritarias de pocas instancias y corpus de entrenamiento muy pequeños. \citet{settles-al-features} han obtenido incluso mejores resultados con esta técnica que con el entrenamiento tradicional usando instancias.

Un enfoque novedoso que combina todos los conceptos anteriores es el de \citet{dualist} en Dualist. Esta herramienta optimiza el aprendizaje activo preguntado al usuario sobre instancias y características de las mismas. Junto con este desarrollo también incluye una serie de investigaciones sobre el rendimiento de tareas de clasificación con usuarios reales y simulados. Es por ello que tomamos como base este trabajo y lo adaptamos con una nueva implementación a nuestro problema.

Para llevar a cabo esta tesis implementaremos un marco de trabajo para el entrenamiento de un clasificador bayesiano ingenuo con aprendizaje activo sobre instancias y características. Aplicaremos este marco de trabajo al problema particular de clasificación de preguntas para Quepy eligiendo para ello un espacio de representación adecuado y entrenando el clasificador. Finalmente realizaremos experimentos que demuestran la utilidad de un sistema de estas características y determinan los mejores parámetros para el entrenamiento.

